人工智能路线



# 分类任务：

## LeNet

## Alexnet

Krizhevsky等提出了AlexNet这种基于卷积神经网络的图像分类器，并赢得了ILSVRC2012年挑战赛的冠军，其达到了比当时最好的模型还要高的性能（超过26%）。AlexNet包括8个可学习的层：5个卷积层、3个全连接层。最后一个全连接层连接到N-Way（N为类别个数）softmax分类器。AlexNet使用了多种卷积核来获取图像特征，也使用了dropout和ReLU分别进行正则化和加速训练。其再次让卷积神经网络进入公众视野，并很快引起了一系列研究热潮。


## ZFNet

## Googlenet

尽管分类网络正在朝着更快、更精确的网络迈进，但由于它们是资源密集型的，在现实世界的应用中部署它们仍有很长的路要走。随着网络规模的扩大以获得更好的性能，计算成本呈指数级增长。Szegedy等人认为造成这种情况的主要原因是网络中计算的浪费，更大的模型通常有更多的参数量，并趋向于过拟合。他们提出用局部稀疏连接架构代替全连接架构，以解决这些问题。GoogleNet是一个22层的网络，由多个Inception模块相互堆叠而成。Inception模块是在同一级别上具有多个大小的卷积核的网络。输入的feature map通过这些卷积核之后，连接到下一层。该网络在中间层还具有辅助分类器，以进行正则化和促进梯度传递。GoogLeNet展示了计算块的高效使用可以与其他参数较多的网络相提并论。其在没有外部数据的情况下，仅用ImageNet即可实现93.3%的top-5精度，同时比其他同时代的模型更快。后续几个迭代的版本进一步提高了性能，并进一步证明了精细化稀疏连接架构的应用。


## VGGnet

当AlexNet及其继任者ZFNet专注于更小的感受野窗口大小来提升准确率时，Simonyan和Zisserman开始研究网络深度的影响。他们提出了VGG，一种使用了更小的卷积核来构造不同深度的网络。由于大感受野可以通过堆叠一系列更小的卷积核来实现，且这样可以大大降低参数量，并能很快收敛。其文章展示了多深的网络（16~19层）可以用于分类和定位，且具备高精度。VGG包含了一系列卷积层+3个全连接，再接一个softmax层。卷积层的个数从8到16不等：首先，最小的11层架构通过随机初始化进行训练，然后用其权重训练更大的网络，以防止梯度不稳定。在单一网络性能类别中，VGG的表现超过了2014年ILSVRC的获奖者GoogleNet，并很快成为了目标分类和检测模型中最常用的backbone。


## Resnet

随着CNNs越来越深，Kaiming He等人表明了网络精度是如何达到饱和并迅速下降的。他们提出了使用残差学习来堆叠卷积层，以减缓精度下降。它是通过在层之间添加跳跃连接来实现的。这种连接是块的输入和输出之间的元素加法，不会给网络增加额外的参数或计算复杂度。一个典型的34层ResNet基本上是一个大的(7x7)卷积核，然后是16个bottleneck模块(一对小的3x3滤波器，在它们之间有恒等的跳跃连接)，最后是一个全连接层。bottleneck模块通过堆叠3个卷积层（1x1,3x3,1x3）可以适应更深的网络。Kaiming He等还表明了VGG16的计算复杂度相当于ResNet104和152，且精度更低。在随后的文章中，作者提出了Resnetv2，在block中使用了BN和ReLu，使得更通用且更容易训练。ResNets称为了广泛应用于分类和检测的backbone，且其思想启发了很多其他的网络。

## ResNeXt

现有的提高模型精度的传统方法是增加模型的深度或宽度。然而，增加任何一种都会导致模型的复杂性和参数的数量增加，而增益迅速减少。 Xie等人提出了ResNeXt架构，它比现有的其他模型更简单、更高效。ResNeXt的灵感来自于VGG/ResNet中相似块的堆叠，以及Inception模块中的“分离-转换-合并”方式。它本质上是一个ResNet，其中每个ResNet块被一个类似于Inception的ResNeXt模块替换，inception的复杂、定制的转换模块被ResNeXt块中的拓扑结构相同的模块所取代，使得网络更容易扩展和泛化。Xie等人还强调，可以将基数(ResNeXt块中的拓扑路径)与深度和宽度一起视为第三维，以提高模型的精度。ResNeXt优雅而简洁。与类似的深度ResNet体系结构相比，它获得了更高的精度，同时拥有更少的超参数。它也是ILSVRC 2016年挑战赛的第一名。


## Densenet

## CSPNet

现有的神经网络已经在计算机视觉任务中取得了令人难以置信的结果;然而，它们依赖于过多的计算资源。Wang等人认为通过减少网络中重复的梯度信息可以减少大量的推理计算。他们提出了CSPNet[25]，它为网络内的梯度流创建不同的路径。CSPNet将底层的feature map分为两部分：其中一部分送入卷积网络块(例如，DenseNet中的Dense和Transition块或ResNeXt中的Res(X)块)，而另一部分在后期与第一部分的输出相结合。这减少了参数的数量，提高了计算单元的利用率，并减少了内存占用。它很容易实现，而且足够通用，可以应用于其他架构，如ResNet， ResNeXt， DenseNet， Scaled-YOLOv4等。在这些网络中应用CSPNet可将计算量减少了10%~20%，而准确性保持不变或有所提高。该方法也大大降低了内存开销和计算瓶颈。它被用于许多先进的检测器模型，同时也被用于移动设备和边缘设备。



## EfficientNet

Tan等人系统研究了网络尺度及其对模型性能的影响。他们总结了改变网络参数如深度、宽度和分辨率是如何影响其准确性的。单独缩放任何参数都会带来相关的成本。增加网络的深度可以帮助捕获更丰富和更复杂的特征，但由于消失梯度问题，它们难以训练。同样地，缩放网络宽度会使捕获细粒度特征更容易，但难以获得高层次的特征。从增加图像分辨率(如深度和宽度)中获得的收益随着模型比例的增加而饱和。Tan等人提出使用一个复合系数，可以均匀地缩放所有三个维度。每个模型参数都有一个相关的常数，它是通过固定系数为1并在baseline网络上执行网格搜索来找到的。基线架构的灵感来自于他们之前的工作（MnasNet），它是通过对搜索目标进行神经架构搜索而开发的，同时优化了精度和计算。EfficientNet是一个简单而高效的架构。它在精度和速度上都优于现有的模型，而且体积要小得多。通过极大地提高效率，它有可能开启一个efficient networks的新时代。



# 目标检测

## R-CNN

![img](https://pic1.zhimg.com/80/v2-a440c3949244da3127eb73844817ef70_720w.jpg)

R-CNN（Region with CNN Feature）2014年提出，在此之前都是传统的目标检测算法，人为定义特征进行检测，进入了瓶颈期，进步缓慢，但是R-CNN出来之后将目标检测领域的准确率至少提高了30%。

![img](https://pic4.zhimg.com/80/v2-a17329a888c5834dec7ea39328572a83_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-f17dbea87dd857d7ba9398a478e769e2_720w.jpg)



## SPP-Net

He等人提出使用空间金字塔池化（SPP）层来处理任意尺寸、任意长宽比的图片。他们意识到，仅全连接层需要固定大小的输入。SPP-net在region proposal module之前，只是平移了CNN的卷积层，增加了pooling层，使得网络不依赖于size/aspect ratio，减少了计算量。生成候选窗口的算法仍是选择性搜索（SS）。feature maps是通过ZF-5网络的卷积层从输入图像提取的。然后，候选窗口被映射到特征映射上，这些特征映射随后被金字塔池化层的空间bins转换为固定长度的表示。最后将得到的向量送入全连接层，然后使用SVM分类器预测类别和得分。类似于R-CNN，SPP-Net也有一个边框回归的后处理层来改善定位精度。其同样使用多阶段训练过程，除了微调以外，其他步骤只在全连接层上进行。

SPP-Net在相似精度的前提下，比R-CNN快很多，它还可以处理任意尺寸、比例的图像，因此，也避免了由于输入形变导致的目标变形。然而，由于其架构类似于R-CNN，它也有R-CNN的缺点，像多阶段训练，昂贵的计算和训练时间。


## Fast R-CNN

![img](https://pic1.zhimg.com/80/v2-0f20cd3187123f9026159dfad5de8838_720w.jpg)

![img](https://pic1.zhimg.com/80/v2-00b303d012b0cb5fa8dea1a11241bbb0_720w.jpg)

## Faster R-CNN

![img](https://pic2.zhimg.com/80/v2-b51f5260c2c32705eab3177917d1ad4d_720w.jpg)

![img](https://pic2.zhimg.com/80/v2-376ada0b67713ba5565aa4a47ab8e9c5_720w.jpg)

![img](https://pic4.zhimg.com/80/v2-559151afed084b7b583c0df41002b0a3_720w.jpg)

![img](https://pic2.zhimg.com/80/v2-15cdfe2dc044f9dacb8b1f145da18c7d_720w.jpg)

![img](https://pic4.zhimg.com/80/v2-f9949469edd52a4e0a1d7620fe6e6437_720w.jpg)

R-CNN经过一步步的改进和优化到最后演变成Faster R-CNN，真正是实现了一种端到端的网络模型，可以达到一张图片输入网络经过预测输出一张检测的效果图。

## FPN

在提升小目标检测效果时，在多个级别上使用图像金字塔来获取特征金字塔（特征化的图像金字塔）是一种常用的手段。虽然它提高了检测器的平均精度，但推理时间的增加也是很多的。Lin等人提出了该特征金字塔网络(FPN)，它采用自上而下的横向连接架构，在不同的尺度上构建高层次的语义特征。FPN有两条路径，一条是由卷积神经网络(ConvNet)在多个尺度上计算特征层次的自底向上路径，另一条是自上而下的路径，它将粗特征图从较高层次上采样为高分辨率特征。这些路径通过1x1卷积运算进行横向连接，以增强特征中的语义信息。这里采用FPN作为Faster R-CNN的RPN，以ResNet-101为backbone。

FPN可以在所有尺度上提供高级语义，降低了检测的错误率。它成为了未来检测模型的标准构建块，提高了整体的准确性。它也促进了洽谈改进的网络，如PANet、NAS-FPN、EfficientNet等网络的发展。

## R-FCN
Dai等人提出基于区域的全卷积神经网络（R-FCN），共享了网络中几乎所有的计算，不像之前的两阶段检测器那样每个proposals都使用了资源密集型技术。他们反对使用完全连接的层，而是使用了卷积层。然而，卷积网络的深层是平移不变的，这使得它们在定位任务中不起作用。作者建议使用位置敏感评分图来补救。这些敏感的评分maps编码了相关的空间信息，并稍后汇集，以确定准确的定位。R-FCN通过将ROI分为k*k个网格，并计算每个cell的得分，然后这些得分求均值，用于预测目标类别。R-FCN检测器是四个卷积网络的组合：输入图像首先经过ResNet-101来获取feature maps；中间输出（Conv4）送入RPN以确定ROI proposals，最后的输出进一步送入一个卷积层进行处理，并送入分类器和回归器。分类层通过结合生成的位置敏感map和RoI proposals来生成预测，而回归网络输出边框的细节。R-FCN采用与Faster-RCNN类似的4步训练方式，同时使用组合交叉熵和边框回归损失。同时，在训练过程中也使用了在线难例挖掘（OHEM）。

Dai等人提出了一种新的方法来解决卷积神经网络中的平移不变性问题。R-FCN将Faster R-CNN和FCN结合起来，实现快速、更准确的检测器。尽管它的准确率没有提高多少，但它比同类产品的速度快2.5-20倍。

## MaskR-CNN
Mask R-CNN在Faster R-CNN基础上进行了扩展，通过增加一个分支来并行进行像素级目标实例分割。该分支是一个应用于RoI上的全连接网络，对每个像素进行分割，整体代价很小。它使用类似于Faster R-CNN的架构进行目标proposals提取，不过增加了一个与分类、回归head并行的mask head。一个主要的区别是使用了RoIAlign层，而不是RoIPool层，以避免由于空间量化造成的像素级错位。为了更好的准确性和速度，作者选择了带有特征金字塔网络(FPN)的ResNeXt-101作为其主干。原先Faster R-CNN中的损失函数更新为了mask loss，就像FPN中那样，它使用了5个anchor、3种长宽比。Mask R-CNN的整体训练与faster R-CNN相似。

Mask R-CNN的性能比现有的SOTA一阶段模型架构更好，增加了一个额外的实例分割功能，但增加的开销很小。该算法训练简单、灵活，在关键点检测、人体姿态估计等应用中具有很好的通用性。然而，它仍然低于实时性能(>30 fps)。

## DetectoRS
许多当代的两阶段探测器采用的是多看多想的机制，即先计算对象proposals，然后提取特征来检测对象。DetectoRS在网络的宏观和微观层面都使用了该机制。在宏观层面，其提出了递归特征金字塔（RFP），这是由多个特征金字塔（FPN）堆叠而成、且带有从FPN的自顶向下层级到自底向上层之间的额外反馈连接。FPN的输出经过空洞空间金字塔池化层（ASPP）处理，然后送入下一个FPN层。然后，通过一个融合模块创建一个注意力map，将不同模块的FPN的输出联合起来。在微观层面，Qiao等人提出了可切换的Atrous卷积(SAC)，以调节卷积的扩张率。利用具有5x5滤波器和1x1卷积的平均池化层作为交换函数来决定atrous卷积[55]的速率，帮助backbone动态检测各种尺度的目标。他们还把SAC放在两个全局上下文模块之间，因为这有助于实现更稳定的切换。递归特征金字塔和可切换Atrous两种技术的结合卷积产生检测器。作者将上述带有混合任务级联(HTC)的技术作为baseline，并和ResNext-101骨干结合起来。

DetectoRS结合了多个系统，以提高探测器的性能，并设置了最先进的两级探测器。其RFP和SAC模块具有很好的通用性，可用于其它检测模型。但是，由于它只能处理数据，不适合实时检测（每秒4帧）。




## SSD

![img](https://pic2.zhimg.com/80/v2-b378cac197fa0bb964674bbb41a5fefd_720w.jpg)

SSD是一种经典的One-Stage算法，它解决当时Faster R-CNN对小目标检测效果差和检测速度慢的问题。SSD可以预测不用尺度的目标，它的网络有6个输出特征层。

![img](https://pic4.zhimg.com/80/v2-192e261d5afe097abdcba6204c20346f_720w.jpg)

使用Faster R-CNN在单GPU上大概每秒6、7张图片；而使用SSD算法，同样在单GPU上它每秒能检测50 、60 张图片；但相比之前使用了FPN的Faster R-CNN而言呢，SSD算法的检测精度要差很多。RetinaNet也是使用ResNet和fpn作为检测模型的backbone，它相比我们使用了FPN的Faster RCNN算法而言，检测精度基本差不多，但是检测速度翻了一番。

## YOLOv1

YOLO系列算法是目前使用最多的目标检测算法，它最大的特点就是检测速度快，而且现在检测精度也就是mAP也变高了，所以称为时下最热门的目标检测算法。它一共有5个版本，YOLO v1到v3是同一个作者Joseph设计的，包括论文到算法结构，YOLO v4到v5是其他作者设计的，目前YOLO v4已有论文和算法，但是YOLO v5只有算法，还没有发表论文，目前检测效果最好和使用最多的就是YOLO v5，所以如果有要发论文的小伙伴，可以使用YOLO v5跑自己的项目或者是改进YOLO v5算法去发论文。下面简单地介绍一下几个版本。



![img](https://pic2.zhimg.com/80/v2-7ca2d50d83cfe0f3bc6438695a705c9d_720w.jpg)

存在的问题：

1、对群体性的小目标检测很差， 比如一群鸟飞过就很难检测，原因是目标小而且密集。

2、当目标出现新的尺寸或比例的时候，预测效果会很差。

3、主要错误原因是定位不准确。是由于直接预测目标的边界框参数，而不是像faster RCNN和SSD一样预测的都是基于anchor的微参数

## YOLOv2

![img](https://pic2.zhimg.com/80/v2-b2ba8663456db79abb3d7af12d23ec4d_720w.jpg)

在7个方面做了尝试和改进。

## YOLOv3

![img](https://pic3.zhimg.com/80/v2-0f5be2d3725ba1e1458d3efaa716e8e6_720w.jpg)

至此基本上YOLO系列已经做得很好了，v3版本主要是在损失函数上做了改进，后面的v4和v5版本也基本都是在特征网络和neck上面做了改进，主要是特征提取更准，对不同尺度的目标预测效果更好，速度更快。

## RetinaNet

鉴于单级和两级探测器的精度差异，Lin等人认为单级探测器滞后的原因是“极端的前景-背景类不平衡”。他们提出了一个改造的交叉熵损失，称为Focal Loss作为解决不平衡的手段，通过其中的参数来降低简单样本对loss的贡献度。作者通过一个简单的单级探测器（RetinaNet）证明了它的有效性，通过对输入图像的位置、比例和纵横比进行密集采样来预测目标。该算法使用由特征金字塔网络(FPN)扩充的ResNet作为骨干网络，两个相似的子网络分别进行分类和回归。FPN的每一层都被传递到子网中，使其能够检测出不同规模的目标。分类子网预测每个位置的对象得分，而边框回归子网将每个锚点的偏移量回归到GT。两个子网都是小的FCN，并在各个网络之间共享参数。与之前大多网络不同，作者使用了一个与类别无关的边界框回归变器，发现它们等效。

RetinaNet训练简单，收敛快速，且容易实现。它在精度和运行时间方面都优于两级探测器。RetinaNet还通过引入新的损失函数来推进目标探测器优化的方法。

## EfficientDet

EfficientDet构建了具有更高精度和效率的可扩展检测器的思想，引入了有效的多尺度特征、BiFPN和模型缩放。BiFPN是一种具有可学习权值的双向特征金字塔网络，用于不同尺度下输入特征的交叉连接，它在NAS-FPN的基础上，通过删除一个输入节点，增加一个额外的横向连接，改进了需要大量训练和复杂网络的NAS-FPN，这消除了低效节点，增强了高级特征融合。与现有的探测器不同的是，它可以根据更大、更深的骨干网络或堆叠FPN层进行放大，EfficientDet引入了一个复合系数，可用于“联合放大骨干网络、BiFPN网络、类/盒网络和分辨率的所有维度”。EfficientDet利用EfficientNet作为backbone，该backbone是一种具有多个BiFPN的堆叠的特征提取网络，最终BiFPN层的每个输出被发送到类和边框预测网络。该模型使用SGD优化器和同步BN进行训练，并使用swish激活，而不是标准的ReLU激活，后者可区分，效率更高，性能更好。

EfficientDet比以前的检测器具有更好的效率和准确性，同时体积更小，计算成本更低。它易于扩展，可以很好地应用于其他任务，并且是当前单阶段对象检测的SOTA模型。

## YOLOv4

![img](https://pic2.zhimg.com/80/v2-e3c6a8c79ad61886db5f1c3cfd5329b5_720w.jpg)

![img](https://pic2.zhimg.com/80/v2-ff971cac2605865139f217d4ad15f7c5_720w.jpg)

网络更加复杂，更加适合使用GPU进行训练。

## CenterNet

Zhou等人采用了一种非常不同的方法：将对象建模为点，而不是传统的边界框表示。CenterNet将对象预测为包围框中心的单个点。输入图像通过FCN生成heatmap，heatmap的峰值对应被检测物体的中心。它使用ImageNet预训练的Hourglass-101作为特征提取网络，有3个head：点目标中心点的heatmap头、目标尺寸wh头、目标中心点偏移头。在训练时，三个头的多任务损失被反向传播到特征提取器中。在推理过程中，利用偏移头的输出来确定对象点，最终生成一个方框。由于预测是点，而不是结果，这里不需要使用非最大抑制(NMS)进行后处理。

CenterNet乜有利用这些年来目标检测的常用套路，而是提出了一个新颖的视角。它比之前的方法更准确，推理时间更短。它具有较高的精度，可用于三维目标检测、关键点估计、姿态、实例分割、方向检测等多种任务。不过在做不同任务时，需要不同的骨干架构，因为一般架构与其他探测器工作良好，性能较差，反之亦然。

关于CenterNet的更多介绍，可以参考：[CenterNet（Objects as Points）：极简Anchor-free目标检测框架]([(14条消息) CenterNet（Objects as Points）：极简Anchor-free目标检测框架_叶舟的博客-CSDN博客](https://blog.csdn.net/oYeZhou/article/details/113350632))、[CenterNet 后处理过程及源码解析]([(14条消息) CenterNet 后处理过程及源码解析_叶舟的博客-CSDN博客_centernet后处理](https://blog.csdn.net/oYeZhou/article/details/111224567))。


## YOLOv5

YOLO v5对应四个模型，分别是V5s，V5m，V5l和V5x。网络组件由三个部分组成。

1）Backbone：在不同图像细粒度上聚合并形成图像特征的卷积神经网络。

2）Neck：一系列混合和组合图像特征的网络层，并将图像特征传递到预测层。

3）output：对图像特征进行预测，生成边界框和并预测类别。

对于YOLOV5，无论是V5s，V5m，V5l还是V5x其Backbone，Neck和output一致。唯一的区别在与模型的深度和宽度设置。

![img](https://pic1.zhimg.com/80/v2-6b86834c083f683c866a9eaff79753d8_720w.jpg)

针对不同的终端，设计了不同的模型。

## YOLOX

## YOLOv6

## Swin Transformer

Transformer从一开始就在自然语言处理(NLP)领域产生了深远的影响。它在语言模型中的应用，如BERT(Bidirectional Encoder Representation from Transformers)，GPT(Generative Pre-trained Transformer)，T5(Text-To-Text Transfer Transformer)等，推动了这一领域的技术进步。transformer[75]使用注意模型来建立序列元素之间的依赖关系，并且可以比其他顺序架构关注更长的上下文。在自然语言处理中的成功引起了人们对其在计算机视觉中的应用的兴趣。而cnn一直是CV的支柱，不过其有一些固有的缺点，如缺乏全局上下文的重要性，固定的训练后权重等。

Swin Transformer旨在为计算机视觉任务提供基于Transformer的backbone，它将输入图像分割成多个不重叠的patch，并将其转换为token。然后将大量Swin Transformer块应用于4个阶段的patch，每个后续阶段减少patch的数量，以保持分层表示。Swin Transformer块由局部多头自注意(MSA)模块组成，在连续块中基于交替移位的patch窗口。在局部自注意中，计算复杂度与图像大小成线性关系，而移动窗口可以实现跨窗口连接。作者还显示了移动的Windows如何在开销很小的情况下提高检测精度。

Transformers提供了一个不同于CNN的范式，不过其在CV领域的应用仍处于初级阶段，它在这些任务中取代卷积的潜力是非常大的。 Swin Transformer在MS-COCO上达到了新的SOTA，不过其参数量相比CNN模型更高。

更多关于Swin Transformer的内容，可以参考：Swin Transformer: 使用滑动窗口的分层视觉transformer。

## DERT



## 轻量网络
近年来，一个新的研究分支已经形成，旨在为物联网中常见的资源受限环境设计小型而高效的网络。这一趋势也渗透到强大的目标检测器的设计中，我们可以看到，虽然大量的目标检测器能够实现很好的准确性和实时推理，但是这些模型大部分需要过多的计算资源，因此不能部署在边缘设备上。

过去，许多不同的方法都显示出令人兴奋的结果。利用高效组件和压缩技术，如剪枝，量化、哈希等提高了深度学习模型的效率。利用训练好的大网络来训练更小的模型，称为蒸馏，也显示了有趣的结果。然而，在本节中，我们将探讨一些在边缘设备上实现高性能的高效神经网络设计的典型例子。列表如下所示：



6.1、SqueezeNet
cnn领域的最新进展主要集中在提高基准数据集的最新精度上，这导致了模型尺寸及其参数的爆炸式增长。但在2016年，Iandola等人提出了一个更小、更智能的网络，称为SqueezeNet，它在保持性能的同时减少了参数。他们采用了三种主要的设计策略，即使用更小的滤波器，将输入通道的数量减少后作为3x3滤波器的输入，以及在网络中更靠后的位置放置下采样层。前两种策略在保持准确性的同时减少了参数的数量，第三种策略增加了网络的准确性。SqueezeNet的构建块称为fire模块，它由两层组成:squeeze层和expand层，每个层都有一个ReLU激活。squeeze层由多个1*1滤波器组成，expand层由一个1*1、3*3混合滤波器组成，从而限制了输入通道的数量。SqueezeNet架构由8个Fire模块穿插在卷积层中间而组成。受ResNet启发，带有残差块的SqueezeNet也被提出，相比普通模型提高了准确率。作者还对深度压缩进行了实验，相比AlexNet，模型尺寸压缩了510倍。SqueezeNet为提高神经网络体系结构的硬件效率提供了一个很好的候选方案。

6.2、MobileNet
MobileNet摆脱了传统小型模型的方法，如收缩、剪枝、量化或压缩，取而代之的是使用高效的网络架构。该网络使用深度可分离卷积，将传统卷积分解为depthwise卷积和1*1的pointwise卷积。一个标准卷积在所有通道上进行卷积，并一次性合并；而深度可分离卷积对输入的每个通道使用不同的卷积核，然后使用pointwise卷积进行合并。这种特征过滤和组合的分离降低了计算成本和模型规模。MobileNet由28个独立的卷积层组成，每个层随后是批处理标准化和ReLU激活功能。Howard等人还引入了两个模型收缩超参数:宽度倍增器和分辨率倍增器，以进一步提高模型的速度和缩小模型的尺寸。宽度倍增器通过减少输入和输出通道来均匀地操纵网络的宽度，而分辨率倍增器影响输入图像的大小及其在整个网络中的表示。MobileNet达到了一些成熟模型的准确率，但模型尺寸只是其数倍之小。Howard等人还展示了它如何在各种应用中进行推广，比如人脸属性、地理定位和目标检测。然而，它像VGG一样过于简单和线性，因此没有太多的通道来实现梯度流，不过在此模型的后期迭代中也得以解决。

6.3、ShuffleNet
2017年，Zhang等人提出了ShuffleNet，这是一种专门为移动设备设计的计算效率极高的神经网络架构。他们认识到，许多高效的网络随着规模的缩小而变得不那么有效，并声称这是由昂贵的1x1卷积造成的。结合信道打乱，他们提出了利用分组卷积来克服其信息流有限的缺点。ShuffleNet主要包括一个标准的卷积，然后是分成三个阶段的ShuffleNet单元。ShuffleNet单元类似于ResNet块，在3x3层使用深度卷积，并将1x1层替换为逐点分组卷积，且在深度卷积层之前有一个通道打乱的操作。ShuffleNet的计算代价可通过两个超参数管理: 组数控制连接稀疏度、缩放因子操纵模型大小。随着组数的增大，错误率会随着每个组的输入通道的减少而饱和，因此可能会降低表示能力。ShuffleNet表现优于当代模且具有相当小的模型尺寸，不过由于ShuffleNet唯一的改进是通道shuffle，因此模型的推理速度没有任何改善。

6.4、MobileNetv2
基于MobileNetv1，Sandler等人于2018提出了MobileNetv2——引入了具有线性瓶颈的反向残差这种新颖的模块，从而降低了计算复杂度并提高了精度。该模块将输入的低维表示扩展为高维，通过深度卷积进行过滤，然后将其投影回低维，不像常见的残差块先压缩、再卷积、最后展开。MobileNetv2包含一个卷积层，随后是19个残差bottleneck块，随后是两个卷积层。只有当stride为1时，残差bottleneck块才有shortcut连接。对于更高的步幅，由于尺寸的差异，不使用shortcut。他们还使用ReLU6作为非线性函数，而不是简单的ReLU，以限制计算。针对目标检测，作者使用MobileNetv2作为backbone，设计了一款SDD，称之为SSDLite，声称拥有比原始SSD少8倍的参数，同时实现具有竞争力的精度。它可以很好地泛化到其他数据集，且易于实现，因此受到社区的好评。

6.5、PeleeNet
现有的轻量级深度学习模型严重依赖深度可分离卷积，缺乏有效的实现。Wang等人提出了一种基于传统卷积的新型高效结构，名为PeleeNet，使用了计算守恒技术。PeleeNet的核心是DenseNet，但参考了许多其他模型的灵感。它引入两路dense层、bottleneck中的动态通道个数、过渡层压缩和传统的后激活，以降低计算成本和提高速度。两路dense层有助于获得不同尺度的接受域，使其更容易识别较大的物体。为了减少信息损失，使用了一个stem块。他们还放弃了DenseNet中使用的压缩因子，因为它损害了特征表达式并降低了准确性。PeleeNet包含了一个stem块、四个阶段的修改后的dense和转化层，以及最后的分类层。作者还提出了一种实时目标检测系统，称为Pelee，它是基于PeleeNet和SSD的变种。与移动设备和边缘设备上的当代检测器相比，它的性能是有所提升的，这表明简单的设计选择可以在整体性能上产生巨大的差异。

6.6、ShuffleNetv2
2018年，马宁宁等人在ShuffleNetv2中提出了一套设计高效网络架构的综合指南，他们主张使用速度或延迟等直接指标来衡量计算复杂度，而不是使用FLOPs等间接指标。ShuffleNetv2建立在四个指导原则上:1)输入和输出通道的宽度相等以最小化内存访问成本，2)根据目标平台和任务仔细选择组卷积，3)多路径结构以效率为代价获得更高的精度，4)像add和ReLU这样的元素操作在计算上是不可忽略的。根据上述原则，他们设计了一个新的构建块，通过通道分离层将输入分成两部分，然后是三个卷积层，这些卷积层与残差连接concat起来并通过一个通道shuffle层。对于下采样模型，去掉了通道分离，且残差连接带有深度可分离卷积层。在两个卷积层之间插入这些块的集合就产生了ShuffleNetv2。作者还对更大的模型(50/162层)进行了实验，获得了更高的精度，但FLOPs增加很少。ShuffleNetv2在计算复杂度方面也优于其他SOTA模型。

6.7、MnasNet
随着各种边缘设备对精确、快速和低延迟模型的需求不断增加，设计这样的神经网络比以往任何时候都更具挑战性。在2018年, Tan等人提出了基于自动神经结构搜索(NAS)方法设计的Mnasnet。他们将搜索问题定义为以高精度和低延迟为目标的多目标优化。它还对搜索空间进行因式分解，将CNN划分为独特的块，然后分别搜索这些块中的操作和连接，从而减少了搜索空间。这也允许每个块有一个独特的设计，不像早期的模型堆叠相同的块。作者使用基于rnn的强化学习代理作为控制器和训练器来测量准确性以及移动设备上的延时。每个采样的模型都在一个任务上进行训练，以获得其准确性，并在实际设备上运行以测试延迟，这用来获取软奖励目标和进行控制器更新。该过程一直重复，直到达到最大迭代次数或者得到一个更优的候选项。其由16个不同的块组成，有一些带有残差连接。MnasNet的速度几乎是MobileNetv2的两倍，且准确率更高。然而，与其他基于强化学习的神经结构搜索模型一样，MnasNet的搜索时间需要海量的计算资源。

6.8、MobileNetv3
MobileNetv3的核心与创建MnasNet的方法相同，只是做了一些修改。一种平台感知的自动神经体系结构搜索是通过NetAdapt在一个分解的层次搜索空间中执行的，它在多次迭代中删除了网络中未充分利用的组件。一旦获得架构方案，它就会对通道进行调整，对权重进行初始化，然后对其进行微调，以改进目标指标。该模型被进一步修改，以删除体系结构中一些计算昂贵的层，并获得额外的延迟优化。Howard等人认为，架构中的滤波器通常是彼此的镜像，即使去掉一半的滤波器也能保持准确性，这样可以减少计算量。MobileNetv3使用了一种混合的ReLU和hard swish作为激活核，后者主要在模型后面使用。hard swish和swish没有明显区别，不过前者在保留精度的同时计算成本更低。对于不同的资源使用用例，作者提出了两种模型：MobileNetv3-Large 和 MobileNetv3-Small。 MobileNetv3-Large由15个bottleneck块组成，而 MobileNetv3-Small由11个bottleneck块组成。其构建块也包含了squeeze和excitation层。类似于MobileNetV2，这些模型在SSDLite中充当特征检测器，比早期的模型快35%，同时实现更高的mAP。

6.9、Once-For-All (OFA)
在过去的几年中，神经体系结构搜索(NAS)的体系结构设计已经产生了很多SOTA，但是，由于样本模型训练，它们的计算成本很高。Cai等提出了一种新的解耦模型训练阶段和神经结构搜索阶段的方法。该模型只训练一次，可以根据需求从中提取子网络。OFA (Once-for-all)网络在深度、宽度、核大小和维数这四个重要维度上为子网络的选择提供了灵活性。由于它们嵌套在OFA网络中，干扰训练，因此引入了渐进收缩。首先，将所有参数设为最大值，训练最大的网络。随后，通过逐步减小内核大小、深度和宽度等参数维度，对网络进行微调。对于弹性核，在大核的中心使用小核。当中心被共享时，将使用一个内核转换矩阵来维持性能。为了改变深度，仅用大网络的前几层，后面的层将跳过。弹性宽度则利用了一个通道排序操作，重新分配通道，且在较小的模型中使用最重要的核。OFA在ImageNet中，以80%的top-1准确率达到了SOTA，并因其将GPU训练时间降低了好几个数量级，在低功耗CV挑战赛（LPCVC）中取得第四的成绩。它展示了为各种硬件需求设计轻量级模型的新范式。

7、结果对比

![img](https://img-blog.csdnimg.cn/20210520135852863.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29ZZVpob3U=,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20210520135910185.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L29ZZVpob3U=,size_16,color_FFFFFF,t_70)



# NLP

## BERT

## Transformer

