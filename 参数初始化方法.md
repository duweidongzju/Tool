参数初始化方法

所有参数值一样，意味着不同的结点根本无法学习到不同的特征，通过不同结点的输出值始终是相同的。这就失去了神经网络特征学习的意义。换句话说，每层所有结点的值都一样，就相当于该层只有一个结点发挥了作用。因此初始化全为0很有可能导致模型失败，无法收敛。这种现象称为“对称权重现象”